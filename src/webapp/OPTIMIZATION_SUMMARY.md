# ğŸš€ Webapp Real-time Optimization Summary

## ğŸ“Š Váº¥n Ä‘á» ban Ä‘áº§u

- âŒ **Response time**: 3-5 giÃ¢y delay
- âŒ **Accuracy**: Dá»± Ä‘oÃ¡n sai nhiá»u dÃ¹ model 97% accuracy
- âŒ **User experience**: Pháº£i Ä‘á»©ng yÃªn 8 frames má»›i nháº­n diá»‡n
- âŒ **Blocking**: Xá»­ lÃ½ tuáº§n tá»±, khÃ´ng async

## ğŸ’¡ Giáº£i phÃ¡p Ã¡p dá»¥ng

### Inspiration: ASL Real-time Demo

Tham kháº£o tá»« `ASL-Real-time-Recognition/real-time demo/demo.py`:

- âœ… **Sliding buffer**: Deque vá»›i maxlen (auto left-shift)
- âœ… **Background threading**: Non-blocking inference
- âœ… **Continuous inference**: KhÃ´ng Ä‘á»£i FSM state
- âœ… **Simple sampling**: Mode 1 thay vÃ¬ mode 2 phá»©c táº¡p

### Thay Ä‘á»•i chi tiáº¿t

#### 1. **server.py** - Core Logic

**TrÆ°á»›c:**

```python
# FSM State Machine
STATE_WAITING â†’ STATE_RECORDING â†’ Inference
- Äá»£i motion detection
- Thu tháº­p frames khi cÃ³ movement
- Chá»‰ infer khi Ä‘á»©ng yÃªn 8 frames
- Blocking inference trong handler
```

**Sau:**

```python
# Sliding Buffer Approach
- Deque vá»›i maxlen=18 (auto drop oldest)
- Má»—i frame â†’ extract keypoints â†’ append to buffer
- Buffer full â†’ trigger background thread inference
- Non-blocking, continuous prediction
```

**Key changes:**

- `BUFFER_SIZE = 18` (giáº£m tá»« 25)
- `MIN_PREDICTION_CONFIDENCE = 0.50` (tÄƒng tá»« 0.35)
- Background `threading.Thread` cho inference
- Loáº¡i bá» motion detection FSM
- Loáº¡i bá» `is_pose_detected` check (Ä‘á»ƒ model quyáº¿t Ä‘á»‹nh)

#### 2. **config.py** - Parameters

**ThÃªm má»›i:**

```python
class WebappConfig:
    SEQ_LEN = 18  # Reduced from 25
    SAMPLING_MODE = "1"  # Mode 1 faster than mode 2
    MIN_CONFIDENCE = 0.50
```

#### 3. **app.js** - Frontend

**Thay Ä‘á»•i:**

- FPS: 25 â†’ 20
- UI: FSM state â†’ Buffer status
- Display: Buffer size, inferring status

#### 4. **index.html** - UI

**Cáº­p nháº­t:**

- Instructions pháº£n Ã¡nh sliding buffer
- Status display: Buffer size / 18 frames
- Inferring indicator

## ğŸ“ˆ Cáº£i thiá»‡n dá»± kiáº¿n

| Metric             | TrÆ°á»›c             | Sau             | Cáº£i thiá»‡n             |
| ------------------ | ----------------- | --------------- | --------------------- |
| **Response time**  | 3-5s              | <200ms          | 15-25x faster âš¡      |
| **Min confidence** | 35%               | 50%             | +43% accuracy ğŸ“ˆ      |
| **User wait**      | Äá»©ng yÃªn 8 frames | Continuous      | Smoother UX âœ¨        |
| **Blocking**       | Yes               | No (threading)  | Better performance ğŸš€ |
| **Sampling**       | Mode 2 (complex)  | Mode 1 (simple) | Faster processing â±ï¸  |

## ğŸ§ª CÃ¡ch test

### 1. Khá»Ÿi Ä‘á»™ng server

```powershell
cd D:\HCMUTE\TLCN\Main\sign_language_video_to_text
.\venv\Scripts\Activate.ps1
python .\src\webapp\server.py
```

### 2. Má»Ÿ browser

```
http://127.0.0.1:5000
```

### 3. Kiá»ƒm tra logs

```powershell
Get-Content logs\webapp.log -Tail 50 -Wait
```

### 4. Metrics cáº§n quan sÃ¡t

**Console logs:**

```
ğŸ” Inference: <label> (0.XXX) | Top3: ...
âœ… Sent: <label> (0.XXX)
```

**UI indicators:**

- Buffer State: "âœ… Buffer Ready" hoáº·c "ğŸ“„ Filling Buffer (X/18)"
- Inferring: "Yes" khi Ä‘ang xá»­ lÃ½
- Prediction hiá»ƒn thá»‹ ngay (<200ms)

**Success criteria:**

- [ ] Buffer fills trong 0.9s (18 frames @ 20 FPS)
- [ ] Inference triggered má»—i khi buffer full
- [ ] Response time < 500ms
- [ ] Confidence > 50% cho predictions
- [ ] Accuracy phÃ¹ há»£p vá»›i training (97%)

## ğŸ”§ Troubleshooting

### Náº¿u váº«n cháº­m:

1. Kiá»ƒm tra `DEVICE` (CUDA vs CPU)
2. Giáº£m `BUFFER_SIZE` xuá»‘ng 15
3. TÄƒng `FPS` lÃªn 15 (giáº£m overhead)

### Náº¿u accuracy tháº¥p:

1. TÄƒng `MIN_PREDICTION_CONFIDENCE` lÃªn 0.60
2. Kiá»ƒm tra camera lighting
3. Review top-3 predictions trong logs

### Náº¿u buffer khÃ´ng fill:

1. Check MediaPipe initialization
2. Verify camera permissions
3. Check WebSocket connection

## ğŸ“ Technical Details

### Buffer Flow

```
Frame 1 â†’ [1]
Frame 2 â†’ [1,2]
...
Frame 18 â†’ [1,2,...,18] â†’ INFERENCE (background thread)
Frame 19 â†’ [2,3,...,19] â†’ INFERENCE (if previous done)
```

### Threading Model

```
Main Thread:
  - Receive frames from WebSocket
  - Extract keypoints (MediaPipe)
  - Append to buffer

Background Thread:
  - Sample frames (mode 1)
  - Normalize keypoints
  - Model inference
  - Emit result via SocketIO
```

### Data Pipeline

```
Raw Frame (640x480)
  â†“ MediaPipe
Keypoints (225-dim)
  â†“ Append to deque
Buffer [18 x 225]
  â†“ Sample (mode 1)
Sampled [18 x 225]
  â†“ Normalize
Normalized [18 x 225]
  â†“ Model
Prediction + Confidence
```

## ğŸ¯ Next Steps

### Tá»‘i Æ°u thÃªm (optional):

1. **Model optimization**:
   - Convert to ONNX for faster inference
   - Quantization (FP16)
2. **Preprocessing**:
   - Cache MediaPipe instance
   - Batch normalization
3. **UI/UX**:
   - Add confidence bars
   - Show top-3 predictions
   - Add clear buffer button

### Monitoring:

- Log inference times
- Track confidence distribution
- Monitor WebSocket latency

---

**Author**: Senior AI Engineer  
**Date**: December 2, 2025  
**Approach**: ASL-inspired Sliding Buffer with Background Threading
