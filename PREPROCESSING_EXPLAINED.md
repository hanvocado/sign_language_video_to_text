# ğŸ“š Preprocessing Deep Dive

## ğŸ” Váº¥n Äá» Chi Tiáº¿t

### Táº¡i sao khÃ´ng cÃ³ dá»± Ä‘oÃ¡n?

```python
# Training (Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u nÃ y):
keypoints = normalize(extract(video_frame))
model.train(keypoints)

# Real-time (CÅ¨NG Cáº¬P NHáº¬T):
keypoints = extract(webcam_frame)  # âŒ THIáº¾U normalize!
prediction = model(keypoints)       # âŒ KHÃ”NG KHá»šP!
```

---

## ğŸ§® PhÃ©p ToÃ¡n Normalize

### Input
```
Pose landmarks:  33 landmarks Ã— 3 (x,y,z) = 99 dims
Left hand:       21 landmarks Ã— 3 (x,y,z) = 63 dims  
Right hand:      21 landmarks Ã— 3 (x,y,z) = 63 dims
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:           75 landmarks Ã— 3 = 225 dims
```

### BÆ°á»›c 1: Extract Raw Keypoints
```python
# MediaPipe output (normalized to 0-1 by MediaPipe itself)
keypoints = [
    0.5,  0.3,  0.2,   # Left eye
    0.55, 0.32, 0.21,  # Right eye
    0.45, 0.6,  0.15,  # Left wrist (idx 15)
    0.52, 0.61, 0.16,  # Right wrist (idx 16)
    ...
]
Shape: (225,)  Range: 0-1
```

### BÆ°á»›c 2: Reshape Ä‘á»ƒ Xá»­ LÃ½
```python
# Reshape thÃ nh (75, 3) Ä‘á»ƒ dá»… lÃ m viá»‡c
seq3d = keypoints.reshape(75, 3)

seq3d = [
    [0.5,  0.3,  0.2 ],    # Landmark 0
    [0.55, 0.32, 0.21],    # Landmark 1
    ...
    [0.45, 0.6,  0.15],    # Landmark 15 (LEFT WRIST)
    [0.52, 0.61, 0.16],    # Landmark 16 (RIGHT WRIST)
    ...
]
```

### BÆ°á»›c 3: TÃ­nh Reference Point
```python
# Reference = center giá»¯a 2 cá»• tay
left_wrist  = seq3d[15, :2]   = [0.45, 0.6]
right_wrist = seq3d[16, :2]   = [0.52, 0.61]
ref = (left_wrist + right_wrist) / 2 = [0.485, 0.605]
```

### BÆ°á»›c 4: Center (Dá»‹ch)
```python
# Trá»« reference tá»« táº¥t cáº£ keypoints
seq3d[:, 0] -= ref[0]   # Trá»« x
seq3d[:, 1] -= ref[1]   # Trá»« y

# Sau:
seq3d = [
    [0.5-0.485,   0.3-0.605,    0.2   ],   # [-0.015, -0.305, 0.2]
    [0.55-0.485,  0.32-0.605,   0.21  ],   # [0.065, -0.285, 0.21]
    ...
    [0.45-0.485,  0.6-0.605,    0.15  ],   # [-0.035, -0.005, 0.15]
    [0.52-0.485,  0.61-0.605,   0.16  ],   # [0.035, 0.005, 0.16]
    ...
]
# Giá» 2 cá»• tay á»Ÿ gáº§n origin (0, 0) âœ“
```

### BÆ°á»›c 5: Scale (Chuáº©n HÃ³a KÃ­ch ThÆ°á»›c)
```python
# TÃ­nh bounding box
min_x, min_y = -0.5, -0.7   # Äiá»ƒm min
max_x, max_y = 0.4, 0.3    # Äiá»ƒm max

# Diagonal = âˆš[(max-min)Â² + (max-min)Â²]
diagonal = sqrt((0.4-(-0.5))Â² + (0.3-(-0.7))Â²)
         = sqrt(0.9Â² + 1.0Â²)
         = sqrt(0.81 + 1.0)
         = sqrt(1.81)
         = 1.345

# Chia táº¥t cáº£ keypoints cho diagonal
seq3d[:, 0] /= 1.345
seq3d[:, 1] /= 1.345

# Káº¿t quáº£: táº¥t cáº£ keypoints trong [-1, 1] range âœ“
```

### Output
```python
# Sau normalize:
normalized = [
    [-0.011,  -0.227,   0.2  ],    # X, Y trong [-1, 1]
    [0.048,   -0.212,   0.21 ],
    ...
    [-0.026,  -0.004,   0.15 ],    # 2 cá»• tay á»Ÿ gáº§n (0, 0)
    [0.026,   0.004,    0.16 ],
    ...
]

Shape: (225,)  Range: -1 to 1  âœ“ NORMALIZED
```

---

## ğŸ¯ Táº¡i Sao Cáº§n Normalize?

### 1. Invariant to Scale (Báº¥t Biáº¿n vá» KÃ­ch ThÆ°á»›c)
```
NgÆ°á»i nhá» thá»±c hiá»‡n gesture:
  Left wrist: (0.3, 0.5) â†’ normalized: (-0.1, 0.1)

NgÆ°á»i lá»›n thá»±c hiá»‡n gesture giá»‘ng há»‡t:
  Left wrist: (0.2, 0.3) â†’ normalized: (-0.1, 0.1)  

âœ“ CÃ¹ng káº¿t quáº£ sau normalize!
```

### 2. Invariant to Position (Báº¥t Biáº¿n vá» Vá»‹ TrÃ­)
```
Gesture gáº§n pháº£i:
  Wrist: (0.7, 0.5) â†’ normalized: (-0.2, 0.05)

Gesture gáº§n trÃ¡i:
  Wrist: (0.3, 0.5) â†’ normalized: (-0.2, 0.05)

âœ“ CÃ¹ng káº¿t quáº£ sau normalize!
```

### 3. Fixed Range for Neural Network (Pháº¡m Vi Cá»‘ Äá»‹nh cho NN)
```
Raw input: [0.2, 0.8, 0.1, 0.5, ...]    Range: 0-1
  â†“ Neural network pháº£i há»c trÃªn pháº¡m vi nÃ y
  âŒ Model há»c Ä‘Æ°á»£c trÃªn pháº¡m vi 0-1

Normalized: [-0.5, 0.3, -0.8, 0.1, ...]  Range: -1 to 1
  â†“ Neural network Ä‘Æ°á»£c huáº¥n luyá»‡n
  âœ“ Model khá»›p pháº¡m vi nÃ y
```

---

## ğŸ’¡ VÃ­ Dá»¥ Thá»±c Táº¿

### Scenario: NgÆ°á»i thá»±c hiá»‡n kÃ­ hiá»‡u "ngÆ°á»i"

#### Training Phase
```python
# Frame tá»« video training
frame = Video.read(...)
keypoints = MediaPipe.extract(frame)
    # = [0.5, 0.3, ..., 0.45, 0.6, ..., 0.52, 0.61, ...]

normalized = normalize_keypoints(keypoints)
    # = [-0.01, -0.30, ..., -0.035, -0.005, ..., 0.035, 0.005, ...]

model.train(normalized, label="ngÆ°á»i")
```

#### Real-time Phase (TRÆ¯á»šC FIX)
```python
# Frame tá»« webcam
frame = Webcam.read(...)
keypoints = MediaPipe.extract(frame)
    # = [0.5, 0.3, ..., 0.45, 0.6, ..., 0.52, 0.61, ...]
    # (Giá»‘ng vá»›i training!)

# âŒ NHÆ¯NG KHÃ”NG NORMALIZE!
prediction = model(keypoints)
    # Model: "ÄÃ¢y khÃ´ng pháº£i dá»¯ liá»‡u tÃ´i nháº­n dáº¡ng!"
    # Output: Random, confidence tháº¥p
```

#### Real-time Phase (SAU FIX) âœ…
```python
# Frame tá»« webcam
frame = Webcam.read(...)
keypoints = MediaPipe.extract(frame)
    # = [0.5, 0.3, ..., 0.45, 0.6, ..., 0.52, 0.61, ...]

# âœ… NORMALIZE!
normalized = normalize_keypoints(keypoints)
    # = [-0.01, -0.30, ..., -0.035, -0.005, ..., 0.035, 0.005, ...]
    # (Giá»‘ng training!)

prediction = model(normalized)
    # Model: "ÄÃ¢y lÃ  'ngÆ°á»i'!"
    # Output: ngÆ°á»i, confidence: 0.92 âœ“
```

---

## ğŸ“Š Visualization

### Before Normalize (âŒ SAI)
```
Input Space:                Model Expected Space:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0 ... 1     â”‚             â”‚ -2 ... 2         â”‚
â”‚ â”‚           â”‚             â”‚ â”‚â”‚               â”‚
â”‚ â”‚ â€¢ â€¢ â€¢ â€¢   â”‚             â”‚ â”‚â”‚               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       âŒ                           âŒ
    MISMATCH!                  Input khÃ¡c pháº¡m vi
```

### After Normalize (âœ… ÄÃšNG)
```
Input Space:                Model Expected Space:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ -1 ... 1    â”‚             â”‚ -2 ... 2         â”‚
â”‚ â”‚           â”‚             â”‚ â”‚â”‚               â”‚
â”‚ â”‚ â€¢ â€¢ â€¢ â€¢   â”‚             â”‚ â”‚â”‚ â€¢ â€¢ â€¢ â€¢       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       âœ…                          âœ…
    MATCH!                    Input khá»›p pháº¡m vi
```

---

## ğŸ”¬ Code Flow

```python
# Raw keypoints
keypoints = [0.5, 0.3, 0.2, 0.55, 0.32, 0.21, ...]  # 225 dims

# Reshape
seq3d = keypoints.reshape(75, 3)

# Extract wrist positions
lw = seq3d[15, :2]  # [0.45, 0.6]
rw = seq3d[16, :2]  # [0.52, 0.61]

# Reference (center)
ref = (lw + rw) / 2  # [0.485, 0.605]

# Center
seq3d[:, :2] -= ref  # Trá»« reference

# Calculate scale
bbox_diag = |max - min|
scale = sqrt(bbox_diag_xÂ² + bbox_diag_yÂ²)

# Scale
seq3d[:, :2] /= scale

# Reshape back
normalized = seq3d.reshape(225,)

# Result: [-0.01, -0.30, ..., 0.035, 0.005, ...]  Range: -1 to 1 âœ“
```

---

## âœ… Verification

### CÃ¡ch Kiá»ƒm Tra Normalize ÄÃºng

```python
# Sau normalize:
arr = normalize_keypoints(keypoints_array)

print(f"Min: {arr.min()}")     # Should be â‰ˆ -2 to -5
print(f"Max: {arr.max()}")     # Should be â‰ˆ 2 to 5
print(f"Mean: {arr.mean()}")   # Should be â‰ˆ 0
print(f"Std: {arr.std()}")     # Should be â‰ˆ 0.5-1.0

# âœ“ Náº¿u tháº¥y: [-3.2, 2.8, 0.1, 0.7] â†’ Normalize Ä‘Ãºng!
# âŒ Náº¿u tháº¥y: [0.2, 0.8, 0.3, 0.5] â†’ ChÆ°a normalize!
```

---

## ğŸ“ Káº¿t Luáº­n

| Concept | Ã NghÄ©a |
|---------|---------|
| **Raw Keypoints** | Tá»a Ä‘á»™ trá»±c tiáº¿p tá»« MediaPipe (0-1 range) |
| **Normalize** | Transform sang fixed range (-1 to 1) |
| **Reference Point** | Center giá»¯a 2 cá»• tay |
| **Scaling Factor** | Diagonal cá»§a bounding box |
| **Invariance** | Báº¥t biáº¿n vá» vá»‹ trÃ­ & kÃ­ch thÆ°á»›c |
| **Why Important** | Model Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u normalized |

**Sá»± thiáº¿u normalize â†’ KhÃ´ng khá»›p dá»¯ liá»‡u training â†’ Dá»± Ä‘oÃ¡n sai**

---

**Status:** âœ… Fixed in `web_app/server.py`  
**Impact:** Predictions now work correctly!
